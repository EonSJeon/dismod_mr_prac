{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 'prevalence' sheet to 'prevalence.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the 'prevalence' sheet using openpyxl\n",
    "df = pd.read_excel(\n",
    "    'full_data.xlsx',\n",
    "    sheet_name='Prevalence',\n",
    "    engine='openpyxl'\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('prevalence.csv', index=False)\n",
    "\n",
    "print(\"Saved 'prevalence' sheet to 'prevalence.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done — all PMIDs filled and saved to 'prevalence_filled.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the sheet (use openpyxl for .xlsx)\n",
    "df = pd.read_csv('prevalence.csv')\n",
    "\n",
    "# 2. Forward-fill PMID so every row has the correct value\n",
    "df['PMID'] = df['PMID'].ffill()\n",
    "\n",
    "# 3. Save to CSV\n",
    "df.to_csv('prevalence_filled.csv', index=False)\n",
    "\n",
    "print(\"Done — all PMIDs filled and saved to 'prevalence_filled.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved with columns: index, sex, area, effective_sample_size, data_type, type, value, standard_error, age_start, age_end, year_start, year_end.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load and reset index\n",
    "df = pd.read_csv('prevalence_filled.csv').reset_index(drop=True)\n",
    "\n",
    "# 2. Drop rows missing any of the critical fields\n",
    "df = df.dropna(subset=[\n",
    "    'age_start', 'age_end', 'year_start', 'year_end',\n",
    "    'Sample size', 'proportion',\n",
    "    'Type (Any, early to intermediate, late-wet, late-dry)'\n",
    "])\n",
    "\n",
    "# 3. Cast age and year columns to integers\n",
    "for col in ['age_start', 'age_end', 'year_start', 'year_end']:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# 4. Build 'area' from Nation (if non-NA) otherwise Region\n",
    "df['area'] = df['Nation'].fillna(df['Region'])\n",
    "\n",
    "# 5. Set constant data_type = 'p'\n",
    "df['data_type'] = 'p'\n",
    "\n",
    "# 6. Lowercase sex\n",
    "df['sex'] = df['Sex'].str.lower()\n",
    "\n",
    "# 7. Reset index into its own column, then select & reorder (including Type)\n",
    "out = df.reset_index()[[\n",
    "    'index',\n",
    "    'sex',\n",
    "    'area',\n",
    "    'Sample size',\n",
    "    'data_type',\n",
    "    'Type (Any, early to intermediate, late-wet, late-dry)',\n",
    "    'proportion',\n",
    "    'standard error',\n",
    "    'age_start',\n",
    "    'age_end',\n",
    "    'year_start',\n",
    "    'year_end'\n",
    "]].rename(columns={\n",
    "    'Sample size': 'effective_sample_size',\n",
    "    'proportion': 'value',\n",
    "    'standard error': 'standard_error',\n",
    "    'Type (Any, early to intermediate, late-wet, late-dry)': 'type'\n",
    "})\n",
    "\n",
    "# 8. Save final CSV\n",
    "out.to_csv('prevalence_filled_selected.csv', index=False)\n",
    "\n",
    "print(\"Saved with columns: index, sex, area, effective_sample_size, data_type, type, value, standard_error, age_start, age_end, year_start, year_end.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late                     1555\n",
      "Early to intermediate     978\n",
      "Any                       939\n",
      "Late-dry                  712\n",
      "Late-wet                  707\n",
      "Intermediate              612\n",
      "Early                     254\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load\n",
    "df = pd.read_csv('prevalence_filled_selected.csv')\n",
    "\n",
    "# 2. Normalize: strip spaces, lower-case\n",
    "df['type_norm'] = df['type'].str.strip().str.lower()\n",
    "\n",
    "# 3. Map to canonical labels\n",
    "type_map = {\n",
    "    'late':                   'Late',\n",
    "    'early to intermediate':  'Early to intermediate',\n",
    "    'any':                    'Any',\n",
    "    'late-dry':               'Late-dry',\n",
    "    'late-wet':               'Late-wet',\n",
    "    'intermediate':           'Intermediate',\n",
    "    'early':                  'Early'\n",
    "}\n",
    "df['type'] = df['type_norm'].map(type_map)\n",
    "\n",
    "# 4. (Optional) drop the helper column\n",
    "df = df.drop(columns='type_norm')\n",
    "\n",
    "# 5. Check\n",
    "print(df['type'].value_counts())\n",
    "\n",
    "# 6. Save\n",
    "df.to_csv('prevalence_filled_selected.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns now present: ['index', 'sex', 'area', 'effective_sample_size', 'data_type', 'value', 'standard_error', 'age_start', 'age_end', 'year_start', 'year_end']\n",
      "\n",
      "Saved filtered data without 'type' column to 'prevalence_late_categories.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the selected CSV\n",
    "df = pd.read_csv('prevalence_filled_selected.csv')\n",
    "\n",
    "# 2. Filter to only Late, Late-dry, Late-wet\n",
    "keep_types = ['Late', 'Late-dry', 'Late-wet']\n",
    "df_filtered = df[df['type'].isin(keep_types)].reset_index(drop=True)\n",
    "\n",
    "# 3. Drop the 'type' column entirely\n",
    "df_filtered = df_filtered.drop(columns='type')\n",
    "\n",
    "# 4. Optional: confirm the column has been removed\n",
    "print(\"Columns now present:\", df_filtered.columns.tolist())\n",
    "\n",
    "# 5. Save to a new CSV\n",
    "df_filtered.to_csv('prevalence_late_categories.csv', index=False)\n",
    "\n",
    "print(\"\\nSaved filtered data without 'type' column to 'prevalence_late_categories.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['US' 'Austrailia' 'Netherland' 'Finland' 'Barbados' 'Italy' 'Greece'\n",
      " 'Japan' 'France' 'Iceland' 'India' 'China' '7 countries' 'Norway'\n",
      " 'Estonia' 'Northern Ireland' 'Spain' 'Greenland' 'Brazil' 'Taiwan'\n",
      " 'Singapore' 'Thailand' 'UK' 'Germany' 'Kenya' 'Netherlands' 'South Korea'\n",
      " 'Ireland' 'Algeria' 'Portugal' 'Slovakia' 'Russia' 'Iran']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv('prevalence_late_categories.csv')\n",
    "\n",
    "# Print unique area values\n",
    "print(df['area'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 90 rows with unmapped area.\n",
      "Unmapped area values were: ['7 countries']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the filtered CSV\n",
    "df = pd.read_csv('prevalence_late_categories.csv')\n",
    "\n",
    "# 2. Keep a copy of the original area strings\n",
    "df['orig_area'] = df['area']\n",
    "\n",
    "# 3. Define ISO3 mapping (Greenland → Denmark)\n",
    "area_to_iso = {\n",
    "    'US':               'USA',\n",
    "    'Austrailia':       'AUS',\n",
    "    'Netherland':       'NLD',\n",
    "    'Netherlands':      'NLD',\n",
    "    'Finland':          'FIN',\n",
    "    'Barbados':         'BRB',\n",
    "    'Italy':            'ITA',\n",
    "    'Greece':           'GRC',\n",
    "    'Japan':            'JPN',\n",
    "    'France':           'FRA',\n",
    "    'Iceland':          'ISL',\n",
    "    'India':            'IND',\n",
    "    'China':            'CHN',\n",
    "    'Norway':           'NOR',\n",
    "    'Estonia':          'EST',\n",
    "    'Northern Ireland': 'GBR',\n",
    "    'Spain':            'ESP',\n",
    "    'Greenland':        'DNK',   # Denmark\n",
    "    'Brazil':           'BRA',\n",
    "    'Taiwan':           'TWN',\n",
    "    'Singapore':        'SGP',\n",
    "    'Thailand':         'THA',\n",
    "    'UK':               'GBR',\n",
    "    'United Kingdom':   'GBR',\n",
    "    'South Korea':      'KOR',\n",
    "    'Germany':          'DEU',\n",
    "    'Kenya':            'KEN',\n",
    "    'Ireland':          'IRL',\n",
    "    'Algeria':          'DZA',\n",
    "    'Portugal':         'PRT',\n",
    "    'Slovakia':         'SVK',\n",
    "    'Russia':           'RUS',\n",
    "    'Iran':             'IRN'\n",
    "}\n",
    "\n",
    "# 4. Map area → ISO3\n",
    "df['area'] = df['area'].map(area_to_iso)\n",
    "\n",
    "# 5. Identify unmapped rows\n",
    "mask_unmapped = df['area'].isna()\n",
    "num_dropped = mask_unmapped.sum()\n",
    "unmapped_vals = df.loc[mask_unmapped, 'orig_area'].unique().tolist()\n",
    "\n",
    "# 6. Report which area strings were dropped\n",
    "print(f\"Dropped {num_dropped} rows with unmapped area.\")\n",
    "print(\"Unmapped area values were:\", unmapped_vals)\n",
    "\n",
    "# 7. Drop them and reset index\n",
    "df = df[~mask_unmapped].reset_index(drop=True)\n",
    "\n",
    "# 8. (Optional) remove helper column\n",
    "df = df.drop(columns=['orig_area'])\n",
    "\n",
    "# 9. Save updated CSV\n",
    "df.to_csv('prevalence_late_categories_country_code.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted 588 rows where 'value' was zero.\n",
      "Removed 0 rows where 'value' exceeded 1.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the CSV\n",
    "df.to_csv('prevalence_late_categories_country_code.csv', index=False)\n",
    "\n",
    "# 2. Find rows where value == 0 and fix\n",
    "mask_zero = df['value'] == 0\n",
    "df.loc[mask_zero, 'value'] = 1 / (2 * df.loc[mask_zero, 'effective_sample_size'])\n",
    "df.loc[mask_zero, 'standard_error'] = np.sqrt(\n",
    "    df.loc[mask_zero, 'value'] * (1 - df.loc[mask_zero, 'value']) / df.loc[mask_zero, 'effective_sample_size']\n",
    ")\n",
    "\n",
    "# 3. Cast effective_sample_size to integer\n",
    "df['effective_sample_size'] = df['effective_sample_size'].astype(int)\n",
    "\n",
    "# 4. Drop rows where value > 1\n",
    "mask_gt1 = df['value'] > 1\n",
    "num_gt1 = mask_gt1.sum()\n",
    "df = df[~mask_gt1]\n",
    "\n",
    "# 5. Report counts\n",
    "print(f\"Adjusted {mask_zero.sum()} rows where 'value' was zero.\")\n",
    "print(f\"Removed {num_gt1} rows where 'value' exceeded 1.\")\n",
    "\n",
    "# 6. Save back to CSV\n",
    "df.to_csv('input_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dismod_mr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
